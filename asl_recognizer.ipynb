{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sign Language Recognition System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduced notebook solving the 'Sign Language Recognition System' project of the [Udacity's Artificial Intelligence Nanodegree](https://www.udacity.com/course/artificial-intelligence-nanodegree--nd889). \n",
    "\n",
    "Source: https://github.com/udacity/AIND-Recognizer\n",
    "\n",
    "The goal of this project is to build a word recognizer for American Sign Language video sequences, demonstrating the power of probabalistic models.  In particular, this project employs  [hidden Markov models (HMM's)](https://en.wikipedia.org/wiki/Hidden_Markov_model) to analyze a series of measurements taken from videos of American Sign Language (ASL) collected for research (see the [RWTH-BOSTON-104 Database](http://www-i6.informatik.rwth-aachen.de/~dreuw/database-rwth-boston-104.php)).  In this video, the right-hand x and y locations are plotted as the speaker signs the sentence.\n",
    "[![ASLR demo](http://www-i6.informatik.rwth-aachen.de/~dreuw/images/demosample.png)](https://drive.google.com/open?id=0B_5qGuFe-wbhUXRuVnNZVnMtam8)\n",
    "\n",
    "The raw data, train, and test sets are pre-defined. The project comprises three parts: <br>\n",
    "<ol>\n",
    "<li>Create a variety of feature sets</li>\n",
    "<li>Implement three different model selection criterion to determine the optimal number of hidden states for each word model</li>\n",
    "<li>Implement the recognizer and compare the effects the different combinations of feature sets and model selection criteria</li> \n",
    "</ol>\n",
    "\n",
    "\n",
    "This project requires Python 3 and the following Python libraries installed:\n",
    "\n",
    "[NumPy](http://www.numpy.org/), [SciPy](https://www.scipy.org/), [scikit-learn](http://scikit-learn.org/0.17/install.html), [pandas](http://pandas.pydata.org/), [matplotlib](http://matplotlib.org/), [jupyter](http://ipython.org/notebook.html), [hmmlearn](http://hmmlearn.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Features\n",
    "\n",
    "The data handler class `AslDb` creates the initial pandas dataframe as well as dictionaries suitable for extracting data to the [hmmlearn](https://hmmlearn.readthedocs.io/en/latest/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>left-x</th>\n",
       "      <th>left-y</th>\n",
       "      <th>right-x</th>\n",
       "      <th>right-y</th>\n",
       "      <th>nose-x</th>\n",
       "      <th>nose-y</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">98</th>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             left-x  left-y  right-x  right-y  nose-x  nose-y  speaker\n",
       "video frame                                                           \n",
       "98    0         149     181      170      175     161      62  woman-1\n",
       "      1         149     181      170      175     161      62  woman-1\n",
       "      2         149     181      170      175     161      62  woman-1\n",
       "      3         149     181      170      175     161      62  woman-1\n",
       "      4         149     181      170      175     161      62  woman-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from asl_recognizer.asl_data import AslDb\n",
    "\n",
    "asl = AslDb() # initializes the database\n",
    "asl.df.head() # displays the first rows of the asl database, indexed by video and frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left-x         149\n",
       "left-y         181\n",
       "right-x        170\n",
       "right-y        175\n",
       "nose-x         161\n",
       "nose-y          62\n",
       "speaker    woman-1\n",
       "Name: (98, 1), dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asl.df.loc[98,1]  # look at the data available for an individual frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame represented by video 98, frame 1 is shown here:\n",
    "![Video 98](http://www-i6.informatik.rwth-aachen.de/~dreuw/database/rwth-boston-104/overview/images/orig/098-start.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ground position (hand relative to nose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>left-x</th>\n",
       "      <th>left-y</th>\n",
       "      <th>right-x</th>\n",
       "      <th>right-y</th>\n",
       "      <th>nose-x</th>\n",
       "      <th>nose-y</th>\n",
       "      <th>speaker</th>\n",
       "      <th>grnd-ry</th>\n",
       "      <th>grnd-ly</th>\n",
       "      <th>grnd-rx</th>\n",
       "      <th>grnd-lx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">98</th>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             left-x  left-y  right-x  right-y  nose-x  nose-y  speaker  \\\n",
       "video frame                                                              \n",
       "98    0         149     181      170      175     161      62  woman-1   \n",
       "      1         149     181      170      175     161      62  woman-1   \n",
       "      2         149     181      170      175     161      62  woman-1   \n",
       "      3         149     181      170      175     161      62  woman-1   \n",
       "      4         149     181      170      175     161      62  woman-1   \n",
       "\n",
       "             grnd-ry  grnd-ly  grnd-rx  grnd-lx  \n",
       "video frame                                      \n",
       "98    0          113      119        9      -12  \n",
       "      1          113      119        9      -12  \n",
       "      2          113      119        9      -12  \n",
       "      3          113      119        9      -12  \n",
       "      4          113      119        9      -12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asl.df['grnd-ry'] = asl.df['right-y'] - asl.df['nose-y']\n",
    "asl.df['grnd-ly'] = asl.df['left-y'] - asl.df['nose-y']\n",
    "asl.df['grnd-rx'] = asl.df['right-x'] - asl.df['nose-x']\n",
    "asl.df['grnd-lx'] = asl.df['left-x'] - asl.df['nose-x']\n",
    "asl.df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 113, -12, 119]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_ground = ['grnd-rx','grnd-ry','grnd-lx','grnd-ly']\n",
    " #show a single set of features for a given (video, frame) tuple\n",
    "[asl.df.loc[98,1][v] for v in features_ground]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the training set\n",
    "Now that we have a feature list defined, we can pass that list to the `build_training` method to collect the features for all the words in the training set.  Each word in the training set has multiple examples from various videos.  Below we can see the unique words that have been loaded into the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training words: ['JOHN', 'WRITE', 'HOMEWORK', 'IX-1P', 'SEE', 'YESTERDAY', 'IX', 'LOVE', 'MARY', 'CAN', 'GO', 'GO1', 'FUTURE', 'GO2', 'PARTY', 'FUTURE1', 'HIT', 'BLAME', 'FRED', 'FISH', 'WONT', 'EAT', 'BUT', 'CHICKEN', 'VEGETABLE', 'CHINA', 'PEOPLE', 'PREFER', 'BROCCOLI', 'LIKE', 'LEAVE', 'SAY', 'BUY', 'HOUSE', 'KNOW', 'CORN', 'CORN1', 'THINK', 'NOT', 'PAST', 'LIVE', 'CHICAGO', 'CAR', 'SHOULD', 'DECIDE', 'VISIT', 'MOVIE', 'WANT', 'SELL', 'TOMORROW', 'NEXT-WEEK', 'NEW-YORK', 'LAST-WEEK', 'WILL', 'FINISH', 'ANN', 'READ', 'BOOK', 'CHOCOLATE', 'FIND', 'SOMETHING-ONE', 'POSS', 'BROTHER', 'ARRIVE', 'HERE', 'GIVE', 'MAN', 'NEW', 'COAT', 'WOMAN', 'GIVE1', 'HAVE', 'FRANK', 'BREAK-DOWN', 'SEARCH-FOR', 'WHO', 'WHAT', 'LEG', 'FRIEND', 'CANDY', 'BLUE', 'SUE', 'BUY1', 'STOLEN', 'OLD', 'STUDENT', 'VIDEOTAPE', 'BORROW', 'MOTHER', 'POTATO', 'TELL', 'BILL', 'THROW', 'APPLE', 'NAME', 'SHOOT', 'SAY-1P', 'SELF', 'GROUP', 'JANA', 'TOY1', 'MANY', 'TOY', 'ALL', 'BOY', 'TEACHER', 'GIRL', 'BOX', 'GIVE2', 'GIVE3', 'GET', 'PUTASIDE']\n"
     ]
    }
   ],
   "source": [
    "training = asl.build_training(features_ground)\n",
    "print(\"Training words: {}\".format(training.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data in `training` is an object of class `WordsData` defined in the `asl_data` module.  in addition to the `words` list, data can be accessed with the `get_all_sequences`, `get_all_Xlengths`, `get_word_sequences`, and `get_word_Xlengths` methods. We need the `get_word_Xlengths` method to train multiple sequences with the `hmmlearn` library.  In the following example, notice that there are two lists; the first is a concatenation of all the sequences(the X portion) and the second is a list of the sequence lengths(the Lengths portion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-19,  38,  27,  89],\n",
       "        [-19,  38,  23,  89],\n",
       "        [-15,  39,  24,  92],\n",
       "        [-12,  33,  24,  92],\n",
       "        [-12,  33,  24,  92],\n",
       "        [ -9,  32,  24,  92],\n",
       "        [-10,  29,  21,  93],\n",
       "        [-10,  29,  20,  94],\n",
       "        [-10,  29,  20,  94],\n",
       "        [-10,  29,  20,  94],\n",
       "        [-10,  29,  20,  94],\n",
       "        [-10,  29,  20,  98],\n",
       "        [-10,  29,  20,  98],\n",
       "        [ -8,  34,  20,  98],\n",
       "        [ -8,  34,  13, 104],\n",
       "        [-19,  35,  29,  75],\n",
       "        [-19,  35,  29,  75],\n",
       "        [-19,  35,  29,  75],\n",
       "        [-19,  35,  25,  79],\n",
       "        [-19,  35,  22,  80],\n",
       "        [-14,  32,  21,  86],\n",
       "        [-14,  32,  21,  86],\n",
       "        [-14,  32,  14,  90],\n",
       "        [-12,  32,  16,  90],\n",
       "        [-12,  32,  16,  92],\n",
       "        [-12,  32,  15,  94],\n",
       "        [-12,  32,  15,  94],\n",
       "        [-12,  32,  15,  94],\n",
       "        [-12,  32,  15,  94],\n",
       "        [-12,  32,  15,  97],\n",
       "        [-10,  35,  15, 101],\n",
       "        [ -6,  41,  11, 104]]), [15, 17])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.get_word_Xlengths('CHICKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Implementation \n",
    "\n",
    "- normalized Cartesian coordinates\n",
    "- polar coordinates\n",
    "- delta difference\n",
    "- custom features: delta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means = asl.df.groupby('speaker').mean()  # Dataframe with mean grouped by speaker\n",
    "df_std = asl.df.groupby('speaker').std() # Dataframe with standard deviations grouped by speaker\n",
    "\n",
    "# Add features for normalized by speaker values of left, right, x, y, using Z-score scaling (X-Xmean)/Xstd\n",
    "asl.df['left-x-mean']= asl.df['speaker'].map(df_means['left-x'])\n",
    "asl.df['left-y-mean']= asl.df['speaker'].map(df_means['left-y'])\n",
    "asl.df['right-x-mean']= asl.df['speaker'].map(df_means['right-x'])\n",
    "asl.df['right-y-mean']= asl.df['speaker'].map(df_means['right-y'])\n",
    "\n",
    "asl.df['left-x-std']= asl.df['speaker'].map(df_std['left-x'])\n",
    "asl.df['left-y-std']= asl.df['speaker'].map(df_std['left-y'])\n",
    "asl.df['right-x-std']= asl.df['speaker'].map(df_std['right-x'])\n",
    "asl.df['right-y-std']= asl.df['speaker'].map(df_std['right-y'])\n",
    "\n",
    "asl.df['norm-rx'] = (asl.df['right-x'] - asl.df['right-x-mean']) / asl.df['right-x-std']\n",
    "asl.df['norm-ry'] = (asl.df['right-y'] - asl.df['right-y-mean']) / asl.df['right-y-std']\n",
    "asl.df['norm-lx'] = (asl.df['left-x'] - asl.df['left-x-mean']) / asl.df['left-x-std']\n",
    "asl.df['norm-ly'] = (asl.df['left-y'] - asl.df['left-y-mean']) / asl.df['left-y-std']\n",
    "\n",
    "features_norm = ['norm-rx', 'norm-ry', 'norm-lx','norm-ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features for polar coordinate values where the nose is the origin\n",
    "# Note that 'polar-rr' and 'polar-rtheta' refer to the radius and angle\n",
    "asl.df['polar-rr'] = (asl.df['grnd-rx']**2 + asl.df['grnd-ry']**2)**0.5\n",
    "asl.df['polar-rtheta'] = np.arctan2(asl.df['grnd-rx'], asl.df['grnd-ry'])\n",
    "asl.df['polar-lr'] = (asl.df['grnd-lx']**2 + asl.df['grnd-ly']**2)**0.5\n",
    "asl.df['polar-ltheta'] = np.arctan2(asl.df['grnd-lx'], asl.df['grnd-ly'])\n",
    "\n",
    "features_polar = ['polar-rr', 'polar-rtheta', 'polar-lr', 'polar-ltheta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features for left, right, x, y differences by one time step\n",
    "asl.df['delta-rx'] = asl.df['right-x'].diff().fillna(method='bfill')\n",
    "asl.df['delta-ry'] = asl.df['right-y'].diff().fillna(method='bfill')\n",
    "asl.df['delta-lx'] = asl.df['left-x'].diff().fillna(method='bfill')\n",
    "asl.df['delta-ly'] = asl.df['left-y'].diff().fillna(method='bfill')\n",
    "\n",
    "features_delta = ['delta-rx', 'delta-ry', 'delta-lx', 'delta-ly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom feature: delta2\n",
    "\n",
    "Delta difference by two time steps of cartesian coordinates (delta2) was chosen empirically after obtaining better results at the end of the project. In particular, delta2 resulted in better performance that other combinations of the above features, including the former choice 'delta polar for several time steps differences'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>left-x</th>\n",
       "      <th>left-y</th>\n",
       "      <th>right-x</th>\n",
       "      <th>right-y</th>\n",
       "      <th>nose-x</th>\n",
       "      <th>nose-y</th>\n",
       "      <th>speaker</th>\n",
       "      <th>grnd-ry</th>\n",
       "      <th>grnd-ly</th>\n",
       "      <th>grnd-rx</th>\n",
       "      <th>...</th>\n",
       "      <th>polar-lr</th>\n",
       "      <th>polar-ltheta</th>\n",
       "      <th>delta-rx</th>\n",
       "      <th>delta-ry</th>\n",
       "      <th>delta-lx</th>\n",
       "      <th>delta-ly</th>\n",
       "      <th>delta2-rx</th>\n",
       "      <th>delta2-ry</th>\n",
       "      <th>delta2-lx</th>\n",
       "      <th>delta2-ly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">98</th>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>119.603512</td>\n",
       "      <td>-0.100501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>119.603512</td>\n",
       "      <td>-0.100501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>119.603512</td>\n",
       "      <td>-0.100501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>119.603512</td>\n",
       "      <td>-0.100501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>181</td>\n",
       "      <td>170</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>woman-1</td>\n",
       "      <td>113</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>119.603512</td>\n",
       "      <td>-0.100501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             left-x  left-y  right-x  right-y  nose-x  nose-y  speaker  \\\n",
       "video frame                                                              \n",
       "98    0         149     181      170      175     161      62  woman-1   \n",
       "      1         149     181      170      175     161      62  woman-1   \n",
       "      2         149     181      170      175     161      62  woman-1   \n",
       "      3         149     181      170      175     161      62  woman-1   \n",
       "      4         149     181      170      175     161      62  woman-1   \n",
       "\n",
       "             grnd-ry  grnd-ly  grnd-rx    ...        polar-lr  polar-ltheta  \\\n",
       "video frame                               ...                                 \n",
       "98    0          113      119        9    ...      119.603512     -0.100501   \n",
       "      1          113      119        9    ...      119.603512     -0.100501   \n",
       "      2          113      119        9    ...      119.603512     -0.100501   \n",
       "      3          113      119        9    ...      119.603512     -0.100501   \n",
       "      4          113      119        9    ...      119.603512     -0.100501   \n",
       "\n",
       "             delta-rx  delta-ry  delta-lx  delta-ly  delta2-rx  delta2-ry  \\\n",
       "video frame                                                                 \n",
       "98    0           0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "      1           0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "      2           0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "      3           0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "      4           0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "\n",
       "             delta2-lx  delta2-ly  \n",
       "video frame                        \n",
       "98    0            0.0        0.0  \n",
       "      1            0.0        0.0  \n",
       "      2            0.0        0.0  \n",
       "      3            0.0        0.0  \n",
       "      4            0.0        0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delta2: features for left, right, x, y differences by TWO time steps\n",
    "asl.df['delta2-rx'] = asl.df['right-x'].diff(periods=2).fillna(method='bfill')\n",
    "asl.df['delta2-ry'] = asl.df['right-y'].diff(periods=2).fillna(method='bfill')\n",
    "asl.df['delta2-lx'] = asl.df['left-x'].diff(periods=2).fillna(method='bfill')\n",
    "asl.df['delta2-ly'] = asl.df['left-y'].diff(periods=2).fillna(method='bfill')\n",
    "\n",
    "features_custom = ['delta2-rx', 'delta2-ry', 'delta2-lx', 'delta2-ly']\n",
    "asl.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PART 2: Model Selection\n",
    "### Model Selection Tutorial\n",
    "The objective of Model Selection is to tune the number of states for each word HMM prior to testing on unseen data.  In this section you will explore three methods: \n",
    "- Log likelihood using cross-validation folds (CV)\n",
    "- Bayesian Information Criterion (BIC)\n",
    "- Discriminative Information Criterion (DIC) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a single word\n",
    "Now that we have built a training set with sequence data, we can \"train\" models for each word.  As a simple starting example, we train a single word using Gaussian hidden Markov models (HMM).   By using the `fit` method during training, the [Baum-Welch Expectation-Maximization](https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm) (EM) algorithm is invoked iteratively to find the best estimate for the model *for the number of hidden states specified* from a group of sample seequences. For this example, we *assume* the correct number of hidden states is 3, but that is just a guess.  How do we know what the \"best\" number of states for training is?  We will need to find some model selection technique to choose the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sklearn\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "\n",
    "def train_a_word(word, num_hidden_states, features):\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    training = asl.build_training(features)  \n",
    "    X, lengths = training.get_word_Xlengths(word)\n",
    "    model = GaussianHMM(n_components=num_hidden_states, n_iter=1000).fit(X, lengths)\n",
    "    logL = model.score(X, lengths)\n",
    "    return model, logL\n",
    "\n",
    "demoword = 'CHICKEN'\n",
    "model, logL = train_a_word(demoword, 3, features_ground)\n",
    "print(\"Number of states trained in model for {} is {}\".format(demoword, model.n_components))\n",
    "print(\"logL = {}\".format(logL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HMM model has been trained and information can be pulled from the model, including means and variances for each feature and hidden state.  The [log likelihood](http://math.stackexchange.com/questions/892832/why-we-consider-log-likelihood-instead-of-likelihood-in-gaussian-distribution) for any individual sample or group of samples can also be calculated with the `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_stats(word, model):\n",
    "    print(\"Number of states trained in model for {} is {}\".format(word, model.n_components))    \n",
    "    variance=np.array([np.diag(model.covars_[i]) for i in range(model.n_components)])    \n",
    "    for i in range(model.n_components):  # for each hidden state\n",
    "        print(\"hidden state #{}\".format(i))\n",
    "        print(\"mean = \", model.means_[i])\n",
    "        print(\"variance = \", variance[i])\n",
    "        print()\n",
    "    \n",
    "show_model_stats(demoword, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try it!\n",
    "Experiment by changing the feature set, word, and/or num_hidden_states values in the next cell to see changes in values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_testword = 'CHOCOLATE'\n",
    "model, logL = train_a_word(my_testword, 4, features_custom) # Experiment here with different parameters\n",
    "show_model_stats(my_testword, model)\n",
    "print(\"logL = {}\".format(logL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the hidden states\n",
    "We can plot the means and variances for each state and feature.  Try varying the number of states trained for the HMM model and examine the variances.  Are there some models that are \"better\" than others?  How can you tell?  We would like to hear what you think in the classroom online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import (cm, pyplot as plt, mlab)\n",
    "\n",
    "def visualize(word, model):\n",
    "    \"\"\" visualize the input model for a particular word \"\"\"\n",
    "    variance=np.array([np.diag(model.covars_[i]) for i in range(model.n_components)])\n",
    "    figures = []\n",
    "    for parm_idx in range(len(model.means_[0])):\n",
    "        xmin = int(min(model.means_[:,parm_idx]) - max(variance[:,parm_idx]))\n",
    "        xmax = int(max(model.means_[:,parm_idx]) + max(variance[:,parm_idx]))\n",
    "        fig, axs = plt.subplots(model.n_components, sharex=True, sharey=False)\n",
    "        colours = cm.rainbow(np.linspace(0, 1, model.n_components))\n",
    "        for i, (ax, colour) in enumerate(zip(axs, colours)):\n",
    "            x = np.linspace(xmin, xmax, 100)\n",
    "            mu = model.means_[i,parm_idx]\n",
    "            sigma = math.sqrt(np.diag(model.covars_[i])[parm_idx])\n",
    "            ax.plot(x, mlab.normpdf(x, mu, sigma), c=colour)\n",
    "            ax.set_title(\"{} feature {} hidden state #{}\".format(word, parm_idx, i))\n",
    "\n",
    "            ax.grid(True)\n",
    "        figures.append(plt)\n",
    "    for p in figures:\n",
    "        p.show()\n",
    "        \n",
    "visualize(my_testword, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  ModelSelector class\n",
    "Review the `SelectorModel` class from the codebase found in the `my_model_selectors.py` module.  It is designed to be a strategy pattern for choosing different model selectors.  For the project submission in this section, subclass `SelectorModel` to implement the following model selectors.  In other words, you will write your own classes/functions in the `my_model_selectors.py` module and run them from this notebook:\n",
    "\n",
    "- `SelectorCV `:  Log likelihood with CV\n",
    "- `SelectorBIC`: BIC \n",
    "- `SelectorDIC`: DIC\n",
    "\n",
    "You will train each word in the training set with a range of values for the number of hidden states, and then score these alternatives with the model selector, choosing the \"best\" according to each strategy. The simple case of training with a constant value for `n_components` can be called using the provided `SelectorConstant` subclass as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.model_selection import KFold\n",
    "from asl_recognizer.asl_utils import combine_sequences\n",
    "\n",
    "\n",
    "class ModelSelector(object):\n",
    "    '''\n",
    "    base class for model selection (strategy design pattern)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, all_word_sequences: dict, all_word_Xlengths: dict, this_word: str,\n",
    "                 n_constant=3,\n",
    "                 min_n_components=2, max_n_components=10,\n",
    "                 random_state=14, verbose=False):\n",
    "        self.words = all_word_sequences\n",
    "        self.hwords = all_word_Xlengths\n",
    "        self.sequences = all_word_sequences[this_word]\n",
    "        self.X, self.lengths = all_word_Xlengths[this_word]\n",
    "        self.this_word = this_word\n",
    "        self.n_constant = n_constant\n",
    "        self.min_n_components = min_n_components\n",
    "        self.max_n_components = max_n_components\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def select(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def base_model(self, num_states):\n",
    "        # with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "        # warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        try:\n",
    "            hmm_model = GaussianHMM(n_components=num_states, covariance_type=\"diag\", n_iter=1000,\n",
    "                                    random_state=self.random_state, verbose=False).fit(self.X, self.lengths)\n",
    "            if self.verbose:\n",
    "                print(\"model created for {} with {} states\".format(self.this_word, num_states))\n",
    "            return hmm_model\n",
    "        except:\n",
    "            if self.verbose:\n",
    "                print(\"failure on {} with {} states\".format(self.this_word, num_states))\n",
    "            return None\n",
    "\n",
    "\n",
    "class SelectorConstant(ModelSelector):\n",
    "    \"\"\" select the model with value self.n_constant\n",
    "\n",
    "    \"\"\"\n",
    "    def select(self):\n",
    "        \"\"\" select based on n_constant value\n",
    "\n",
    "        :return: GaussianHMM object\n",
    "        \"\"\"\n",
    "        best_num_components = self.n_constant\n",
    "        return self.base_model(best_num_components)\n",
    "\n",
    "\n",
    "class SelectorBIC(ModelSelector):\n",
    "    \"\"\" select the model with the lowest Baysian Information Criterion(BIC) score\n",
    "\n",
    "    http://www2.imm.dtu.dk/courses/02433/doc/ch6_slides.pdf\n",
    "    Bayesian information criteria: BIC = -2 * logL + p * logN\n",
    "    \"\"\"\n",
    "\n",
    "    def select(self):\n",
    "        \"\"\" select the best model for self.this_word based on\n",
    "        BIC score for n between self.min_n_components and self.max_n_components\n",
    "        :return: GaussianHMM object\n",
    "        \"\"\"\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "        # TODO implement model selection based on BIC scores\n",
    "\n",
    "        best_BIC = float('inf')     # hold the lowest BIC found\n",
    "        best_model = None           # hold the model with the lowest BIC found\n",
    "\n",
    "        # main loop: get model and score for different number of hidden states and update best_BIC and best_model\n",
    "        for n_components in range(self.min_n_components, self.max_n_components+1):\n",
    "            logL = None\n",
    "            model = self.base_model(n_components) # avoid code duplication using the inherited method\n",
    "            if model is None:   # failed\n",
    "                continue\n",
    "            try:  # hmmlearn stability issues\n",
    "                logL = model.score(self.X, self.lengths)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # BIC = -2 log L + p log N  (the lower the better)\n",
    "            # p = num free params = transistion probs(n*n) + means(n*f) + covars(n*f)  (feedback from project review)\n",
    "            p = n_components**2 + (2 * len(self.X[0]) * n_components)\n",
    "            BIC = -2 * logL + p * np.log(len(self.X))\n",
    "            if  BIC < best_BIC:\n",
    "                best_BIC = BIC\n",
    "                best_model = model\n",
    "\n",
    "        return best_model\n",
    "\n",
    "\n",
    "class SelectorDIC(ModelSelector):\n",
    "    \"\"\" select best model based on Discriminative Information Criterion\n",
    "\n",
    "    Biem, Alain. \"A model selection criterion for classification: Application to hmm topology optimization.\"\n",
    "    Document Analysis and Recognition, 2003. Proceedings. Seventh International Conference on. IEEE, 2003.\n",
    "    http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.6208&rep=rep1&type=pdf\n",
    "    DIC = log(P(X(i)) - 1/(M-1)SUM(log(P(X(all but i))\n",
    "    \"\"\"\n",
    "\n",
    "    def select(self):\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "        # TODO implement model selection based on DIC scores\n",
    "\n",
    "        best_DIC = float('-inf')    # hold the highest BIC found\n",
    "        best_model = None           # hold the model with the highest BIC found\n",
    "        my_word = self.this_word    # word to evaluate\n",
    "\n",
    "        # main loop: get model and score for different number of hidden states and update best_DIC and best_model\n",
    "        for n_components in range(self.min_n_components, self.max_n_components+1):\n",
    "            logL = None     # likelihood of the trained model\n",
    "            anti_logL = []  # list containing all the anti likelihoods of the trained model\n",
    "            self.this_word = my_word\n",
    "\n",
    "            # train the model for current word (self.this_word)\n",
    "            model = self.base_model(n_components)  # avoid code duplication using the inherited method\n",
    "            if model is None:   # failed\n",
    "                continue\n",
    "            # get the likelihood of the model\n",
    "            try:  # hmmlearn stability issues\n",
    "                logL = model.score(self.X, self.lengths)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # get the anti-likehoods (score every other word for the current model)\n",
    "            for other_word in self.hwords:\n",
    "                if other_word == my_word:\n",
    "                    continue\n",
    "                X, lengths = self.hwords[other_word]\n",
    "                try:  # stability issues for hmmlearn v<0.2.1\n",
    "                    anti_logL.append(model.score(X, lengths))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # I found the docstring formula a bit confusing   DIC = log(P(X(i)) - 1/(M-1)SUM(log(P(X(all but i)) :\n",
    "            # The size of anti_logL is already M-1, as the word evaluated is not included in anti_logL.\n",
    "            # Biem, Alain: \"DIC = Difference between the likelihood of the data an the the average of anti-likelihood\"\n",
    "            # From the paper we can state: DIC = log(P(X(i)) - average(log(P(X(all but i))\n",
    "            DIC = logL - np.average(anti_logL)  # The higher the better\n",
    "            if  DIC > best_DIC:\n",
    "                best_DIC = DIC\n",
    "                best_model = model\n",
    "\n",
    "        return best_model\n",
    "\n",
    "\n",
    "class SelectorCV(ModelSelector):\n",
    "    \"\"\" select best model based on average log Likelihood of cross-validation folds \"\"\"\n",
    "\n",
    "    def select(self):\n",
    "        \"\"\" :return: GaussianHMM object \"\"\"\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "        # TODO implement model selection using CV\n",
    "\n",
    "        # KFold default n_splits = 3 is used here. Sequences of size lower than 3 must be considered:\n",
    "        if len(self.sequences) >= 3:\n",
    "            n_splits = 3\n",
    "        elif len(self.sequences) == 2:\n",
    "            n_splits = 2\n",
    "        else:\n",
    "            # print(\"No Cross Validation is possible for word: \", self.this_word, \"only has 1 occurrence\")\n",
    "            return None\n",
    "\n",
    "        best_score = float('-inf')  # hold the highest average of cross-validation scores found\n",
    "        best_model = None           # hold the model with the highest average of cross-validation score found\n",
    "\n",
    "        # main loop: get model and score for different number of hidden states and update best_score and best_model\n",
    "        for n_components in range(self.min_n_components, self.max_n_components+1):\n",
    "\n",
    "            split_method = KFold(n_splits=n_splits)\n",
    "            logL = []  # list of cross validation scores obtained\n",
    "\n",
    "            # get the model for the combined cross-validation training sequences and score with their combined\n",
    "            #  validation sequences filling the list 'logL'\n",
    "            for cv_train_idx, cv_test_idx in split_method.split(self.sequences):\n",
    "\n",
    "                self.X, self.lengths = combine_sequences(cv_train_idx, self.sequences)\n",
    "                model = self.base_model(n_components)  # avoid code duplication using the inherited method\n",
    "                if model is None:   # failed\n",
    "                    continue\n",
    "\n",
    "                test_X, test_lengths = combine_sequences(cv_test_idx, self.sequences)\n",
    "                try:   # hmmlearn stability issues\n",
    "                    logL.append(model.score(test_X, test_lengths))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if model is None or logL == []:\n",
    "                continue\n",
    "\n",
    "            score = np.mean(logL)  # The higher the better\n",
    "            if  score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = asl.build_training(features_ground)  # Experiment here with different feature sets defined in part 1\n",
    "word = 'CHICKEN' # Experiment here with different words\n",
    "model = SelectorConstant(training.get_all_sequences(), training.get_all_Xlengths(), word, n_constant=3).select()\n",
    "print(\"Number of states trained in model for {} is {}\".format(word, model.n_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-validation folds\n",
    "If we simply score the model with the Log Likelihood calculated from the feature sequences it has been trained on, we should expect that more complex models will have higher likelihoods. However, that doesn't tell us which would have a better likelihood score on unseen data.  The model will likely be overfit as complexity is added.  To estimate which topology model is better using only the training data, we can compare scores using cross-validation.  One technique for cross-validation is to break the training set into \"folds\" and rotate which fold is left out of training.  The \"left out\" fold scored.  This gives us a proxy method of finding the best model to use on \"unseen data\". In the following example, a set of word sequences is broken into three folds using the [scikit-learn Kfold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class object. When you implement `SelectorCV`, you will use this technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "training = asl.build_training(features_ground) # Experiment here with different feature sets\n",
    "word = 'VEGETABLE' # Experiment here with different words\n",
    "word_sequences = training.get_word_sequences(word)\n",
    "split_method = KFold()\n",
    "for cv_train_idx, cv_test_idx in split_method.split(word_sequences):\n",
    "    print(\"Train fold indices:{} Test fold indices:{}\".format(cv_train_idx, cv_test_idx))  # view indices of the folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** In order to run `hmmlearn` training using the X,lengths tuples on the new folds, subsets must be combined based on the indices given for the folds.  A helper utility has been provided in the `asl_utils` module named `combine_sequences` for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scoring models with other criterion\n",
    "Scoring model topologies with **BIC** balances fit and complexity within the training set for each word.  In the BIC equation, a penalty term penalizes complexity to avoid overfitting, so that it is not necessary to also use cross-validation in the selection process.  There are a number of references on the internet for this criterion.  These [slides](http://www2.imm.dtu.dk/courses/02433/doc/ch6_slides.pdf) include a formula you may find helpful for your implementation.\n",
    "\n",
    "The advantages of scoring model topologies with **DIC** over BIC are presented by Alain Biem in this [reference](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.6208&rep=rep1&type=pdf) (also found [here](https://pdfs.semanticscholar.org/ed3d/7c4a5f607201f3848d4c02dd9ba17c791fc2.pdf)).  DIC scores the discriminant ability of a training set for one word against competing words.  Instead of a penalty term for complexity, it provides a penalty if model liklihoods for non-matching words are too similar to model likelihoods for the correct word in the word set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2_submission'></a>\n",
    "### Model Selection Implementation Submission\n",
    "Implement `SelectorCV`, `SelectorBIC`, and `SelectorDIC` classes in the `my_model_selectors.py` module.  Run the selectors on the following five words. Then answer the questions about your results.\n",
    "\n",
    "**Tip:** The `hmmlearn` library may not be able to train or score all models.  Implement try/except contructs as necessary to eliminate non-viable models from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_train = ['FISH', 'BOOK', 'VEGETABLE', 'FUTURE', 'JOHN']\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement SelectorCV in my_model_selector.py\n",
    "\n",
    "# from importlib import reload\n",
    "# import my_model_selectors\n",
    "# reload(my_model_selectors)\n",
    "\n",
    "training = asl.build_training(features_ground)  # Experiment here with different feature sets defined in part 1\n",
    "sequences = training.get_all_sequences()\n",
    "Xlengths = training.get_all_Xlengths()\n",
    "for word in words_to_train:\n",
    "    start = timeit.default_timer()\n",
    "    model = SelectorCV(sequences, Xlengths, word, \n",
    "                    min_n_components=2, max_n_components=15, random_state = 14).select()\n",
    "    end = timeit.default_timer()-start\n",
    "    if model is not None:\n",
    "        print(\"Training complete for {} with {} states with time {} seconds\".format(word, model.n_components, end))\n",
    "    else:\n",
    "        print(\"Training failed for {}\".format(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = asl.build_training(features_ground)  # Experiment here with different feature sets defined in part 1\n",
    "sequences = training.get_all_sequences()\n",
    "Xlengths = training.get_all_Xlengths()\n",
    "for word in words_to_train:\n",
    "    start = timeit.default_timer()\n",
    "    model = SelectorBIC(sequences, Xlengths, word, \n",
    "                    min_n_components=2, max_n_components=15, random_state = 14).select()\n",
    "    end = timeit.default_timer()-start\n",
    "    if model is not None:\n",
    "        print(\"Training complete for {} with {} states with time {} seconds\".format(word, model.n_components, end))\n",
    "    else:\n",
    "        print(\"Training failed for {}\".format(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Implement SelectorDIC in module my_model_selectors.py\n",
    "\n",
    "training = asl.build_training(features_ground)  # Experiment here with different feature sets defined in part 1\n",
    "sequences = training.get_all_sequences()\n",
    "Xlengths = training.get_all_Xlengths()\n",
    "for word in words_to_train:\n",
    "    start = timeit.default_timer()\n",
    "    model = SelectorDIC(sequences, Xlengths, word, \n",
    "                    min_n_components=2, max_n_components=15, random_state = 14).select()\n",
    "    end = timeit.default_timer()-start\n",
    "    if model is not None:\n",
    "        print(\"Training complete for {} with {} states with time {} seconds\".format(word, model.n_components, end))\n",
    "    else:\n",
    "        print(\"Training failed for {}\".format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**  Compare and contrast the possible advantages and disadvantages of the various model selectors implemented.\n",
    "\n",
    "**Answer 2:**\n",
    "\n",
    "**CV**:  Common in supervised learning to avoid partitioning the training set for validation. Among the tree model selectors, CV is the only one (cross)validated with sequences different of the training sets. However the running time needed is higher than direct selectors like BIC, since for each word several models must be created for cross-validation (combinations of training-validation sequences).  \n",
    "\n",
    "**BIC**: Simple selector that penalizes the resulted likelihood with the complexity of the model (more hidden layers increases the risk of overfitting). It needs less running time than CV and DIC, as only one model and one score must be computed per number of hidden nodes. \n",
    "\n",
    "**DIC**: The penalty term in DIC is based on the average likelihood for the other words. That is why it has the highest computational cost of the three: a score for each word of the training set must be computed for each number of hidden states.\n",
    "\n",
    "Further comparisons will be discussed together with the results of the part 3 of the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3_tutorial'></a>\n",
    "## PART 3: Recognizer\n",
    "The objective of this section is to \"put it all together\".  Using the four feature sets created and the three model selectors, you will experiment with the models and present your results.  Instead of training only five specific words as in the previous section, train the entire set with a feature set and model selector strategy.  \n",
    "### Recognizer Tutorial\n",
    "##### Train the full training set\n",
    "The following example trains the entire set with the example `features_ground` and `SelectorConstant` features and model selector.  Use this pattern for you experimentation and final submission cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload for automatically reloading changes made in my_model_selectors and my_recognizer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def train_all_words(features, model_selector):\n",
    "    training = asl.build_training(features)  # Experiment here with different feature sets defined in part 1\n",
    "    sequences = training.get_all_sequences()\n",
    "    Xlengths = training.get_all_Xlengths()\n",
    "    model_dict = {}\n",
    "    for word in training.words:\n",
    "        model = model_selector(sequences, Xlengths, word, \n",
    "                        n_constant=3).select()\n",
    "        model_dict[word]=model\n",
    "    return model_dict\n",
    "\n",
    "models = train_all_words(features_ground, SelectorConstant)\n",
    "print(\"Number of word models returned = {}\".format(len(models)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the test set\n",
    "The `build_test` method in `ASLdb` is similar to the `build_training` method already presented, but there are a few differences:\n",
    "- the object is type `SinglesData` \n",
    "- the internal dictionary keys are the index of the test word rather than the word itself\n",
    "- the getter methods are `get_all_sequences`, `get_all_Xlengths`, `get_item_sequences` and `get_item_Xlengths`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = asl.build_test(features_ground)\n",
    "print(\"Number of test set items: {}\".format(test_set.num_items))\n",
    "print(\"Number of test set sentences: {}\".format(len(test_set.sentences_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3_submission'></a>\n",
    "### Recognizer Implementation Submission\n",
    "For the final project submission, students must implement a recognizer following guidance in the `my_recognizer.py` module.  Experiment with the four feature sets and the three model selection methods (that's 12 possible combinations). You can add and remove cells for experimentation or run the recognizers locally in some other way during your experiments, but retain the results for your discussion.  For submission, you will provide code cells of **only three** interesting combinations for your discussion (see questions below). At least one of these should produce a word error rate of less than 60%, i.e. WER < 0.60 . \n",
    "\n",
    "**Tip:** The hmmlearn library may not be able to train or score all models.  Implement try/except contructs as necessary to eliminate non-viable models from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from asl_recognizer.asl_data import SinglesData\n",
    "\n",
    "\n",
    "def recognize(models: dict, test_set: SinglesData):\n",
    "    \"\"\" Recognize test word sequences from word models set\n",
    "\n",
    "   :param models: dict of trained models\n",
    "       {'SOMEWORD': GaussianHMM model object, 'SOMEOTHERWORD': GaussianHMM model object, ...}\n",
    "   :param test_set: SinglesData object\n",
    "   :return: (list, list)  as probabilities, guesses\n",
    "       both lists are ordered by the test set word_id\n",
    "       probabilities is a list of dictionaries where each key a word and value is Log Liklehood\n",
    "           [{SOMEWORD': LogLvalue, 'SOMEOTHERWORD' LogLvalue, ... },\n",
    "            {SOMEWORD': LogLvalue, 'SOMEOTHERWORD' LogLvalue, ... },\n",
    "            ]\n",
    "       guesses is a list of the best guess words ordered by the test set word_id\n",
    "           ['WORDGUESS0', 'WORDGUESS1', 'WORDGUESS2',...]\n",
    "   \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    probabilities = []\n",
    "    guesses = []\n",
    "    # TODO implement the recognizer\n",
    "\n",
    "    test_sequences = list(test_set.get_all_Xlengths().values()) # extract X and Xlength lists in a variable\n",
    "\n",
    "    # Main loop: iterate for each word sequence and fill the lists probabilities and guesses\n",
    "    for test_X, test_Xlength in  test_sequences:\n",
    "\n",
    "        best_score = float('-inf')  # hold the highest likelihood found for the current sequence\n",
    "        best_word = None            # hold the word with the highest likelihood found for the current sequence\n",
    "        prob_dict = {}              # dictionary to fill before being added to the probabilities list {word: LogL}\n",
    "\n",
    "        # Score the models avaliable for different words for the current sequence, fill prob_dict and update best_score\n",
    "        # and best_word found\n",
    "        for word, model in models.items():\n",
    "            try:  # hmmlearn stability issues\n",
    "                logL = model.score(test_X, test_Xlength)\n",
    "            except:\n",
    "                logL = None\n",
    "\n",
    "            prob_dict[word] = logL\n",
    "            if logL is not None:\n",
    "                if logL > best_score:\n",
    "                    best_score = logL\n",
    "                    best_word = word\n",
    "\n",
    "        probabilities.append(prob_dict)\n",
    "        guesses.append(best_word)\n",
    "\n",
    "    return probabilities, guesses\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     from  asl_test_recognizer import TestRecognize\n",
    "#     test_model = TestRecognize()\n",
    "#     test_model.setUp()\n",
    "#     test_model.test_recognize_probabilities_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asl_recognizer.asl_utils import show_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#  BASE COMBINATION:  SelectorConstant with features_ground.  WER = 0.669\n",
    "\n",
    "# TODO Choose a feature set and model selector\n",
    "features = features_ground # change as needed\n",
    "model_selector = SelectorConstant # change as needed\n",
    "\n",
    "# TODO Recognize the test set and display the result with the show_errors method\n",
    "models = train_all_words(features, model_selector)\n",
    "test_set = asl.build_test(features)\n",
    "probabilities, guesses = recognize(models, test_set)\n",
    "show_errors(guesses, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#  COMBINATION 1:   SelectorCV with features_polar.  WER = 0.607\n",
    "\n",
    "# TODO Choose a feature set and model selector\n",
    "features = features_polar # change as needed\n",
    "model_selector = SelectorCV # change as needed\n",
    "\n",
    "# TODO Recognize the test set and display the result with the show_errors method\n",
    "models = train_all_words(features, model_selector)\n",
    "test_set = asl.build_test(features)\n",
    "probabilities, guesses = recognize(models, test_set)\n",
    "show_errors(guesses, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#  COMBINATION 2:  SelectorBIC with features_polar.  WER = 0.545\n",
    "\n",
    "# TODO Choose a feature set and model selector\n",
    "features = features_polar # change as needed\n",
    "model_selector = SelectorBIC # change as needed\n",
    "\n",
    "# TODO Recognize the test set and display the result with the show_errors method\n",
    "models = train_all_words(features, model_selector)\n",
    "test_set = asl.build_test(features)\n",
    "probabilities, guesses = recognize(models, test_set)\n",
    "show_errors(guesses, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#  COMBINATION 3:  SelectorCV with features_custom(delta2).  WER = 0.539\n",
    "\n",
    "# TODO Choose a feature set and model selector\n",
    "features = features_custom # change as needed\n",
    "model_selector = SelectorCV # change as needed\n",
    "\n",
    "# TODO Recognize the test set and display the result with the show_errors method\n",
    "models = train_all_words(features, model_selector)\n",
    "test_set = asl.build_test(features)\n",
    "probabilities, guesses = recognize(models, test_set)\n",
    "show_errors(guesses, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:**  Summarize the error results from three combinations of features and model selectors.  What was the \"best\" combination and why?  What additional information might we use to improve our WER?  For more insight on improving WER, take a look at the introduction to Part 4.\n",
    "\n",
    "**Answer 3:**\n",
    "\n",
    "A - SelectorCV + features_polar. WER = 0.607  (wall time: 112s)\n",
    "\n",
    "B - SelectorBIC + features_polar. WER = 0.545  (wall time: 71s)\n",
    "\n",
    "C - SelectorCV  + features_custom(delta2). WER = 0.539  (wall time: 118s)\n",
    "\n",
    "The best combination, SelectorCV + features_custom(delta2), is mainly due to an acurrate choice for the custom features \"delta2\":\n",
    "- With normalized features, the recognizer always performed worse than with the other features analyzed. \n",
    "- With polar features, less than 60% could be achieved with DIC and BIC only (54.4%). \n",
    "- With delta features, however, the recognizer never produced a word error rate lower than 60%, being the best result, 61.2%, obtained with selectorCV. \n",
    "- After using the custom \"delta2\" features it was easy to get error rates lower than 60% for the three model selectors, allowing a better comparison of the them, where SelectorCV had a better performance than BIC and DIC (opposite to using polar features)\n",
    "\n",
    "Attending the running time, BIC model selector is the fastest for all tests for the reasons discussed in part 2 followed by Cross-Validation (~1.5 times longer), and finally DIC (~3 times longer). DIC was discarded after the first combinations since similar or better performances were usually reached with cross-validation and BIC, also needing less running time.\n",
    "\n",
    "Finally, to improve our WER we could modify \"delta2\" or \"polar\" including terms from other features or combinations of features (linear function, etc.). Other variables like zoom and hand orientations, unavailable in this project, could help to elaborate more accurate features.\n",
    "\n",
    "A better option is to include statistical data (as suggested in the lesson and also proposed in the optional exercise) with information about the occurrence of a word in a sentence, or the probability of the word to appears next to other words (biased priors could be created before training). By using semantics rules, for example, a heuristic strategy based on previous sequences could restrict the search to meaningful words only. \n",
    "\n",
    "Moreover, as we are using ordered sequences, we could implement a recurrent neural network (LSTM) to improve our WER.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbpresent": {
   "slides": {
    "0a2d4faf-9fb8-4cee-853b-ed68b90f3f8a": {
     "id": "0a2d4faf-9fb8-4cee-853b-ed68b90f3f8a",
     "prev": null,
     "regions": {
      "3fb9ce83-fbb2-4995-832a-f8f400734ad3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "1dbb9346-179b-4835-b430-6369d88f1a1b",
        "part": "whole"
       },
       "id": "3fb9ce83-fbb2-4995-832a-f8f400734ad3"
      }
     }
    },
    "1519a4fa-1588-4644-98de-9c43bf0aceb5": {
     "id": "1519a4fa-1588-4644-98de-9c43bf0aceb5",
     "prev": "8a712017-49b7-449f-8264-43a032ace902",
     "regions": {
      "29546121-ed11-44b7-8144-0c44e874098f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "365590a4-6963-4812-a1cf-688f7b6bb9ff",
        "part": "whole"
       },
       "id": "29546121-ed11-44b7-8144-0c44e874098f"
      }
     }
    },
    "176eaccb-15dd-455d-bf07-504213e7aa01": {
     "id": "176eaccb-15dd-455d-bf07-504213e7aa01",
     "prev": "de6b30f4-2463-4901-92ed-aabad78e5e0f",
     "regions": {
      "1542aa9e-dc55-4b90-adef-bf5181872b42": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5c242050-c1f7-4b3b-8103-2ea9d71a40dc",
        "part": "whole"
       },
       "id": "1542aa9e-dc55-4b90-adef-bf5181872b42"
      }
     }
    },
    "19091b36-b0e7-49b1-b501-ec05937e0da9": {
     "id": "19091b36-b0e7-49b1-b501-ec05937e0da9",
     "prev": "1983c02e-fb99-4c05-a728-e0c0ad7c06d8",
     "regions": {
      "6529a31c-8d45-425c-b1d7-d0ac6fca6a32": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e766909d-9421-4aaf-9fb1-bc90d27e49e3",
        "part": "whole"
       },
       "id": "6529a31c-8d45-425c-b1d7-d0ac6fca6a32"
      }
     }
    },
    "1983c02e-fb99-4c05-a728-e0c0ad7c06d8": {
     "id": "1983c02e-fb99-4c05-a728-e0c0ad7c06d8",
     "prev": "176eaccb-15dd-455d-bf07-504213e7aa01",
     "regions": {
      "1c4e605d-7f22-4f30-b3fb-74b2937e7a4a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4d217204-e5c0-4568-bd30-12c2e41b681d",
        "part": "whole"
       },
       "id": "1c4e605d-7f22-4f30-b3fb-74b2937e7a4a"
      }
     }
    },
    "212b111f-4527-459c-8297-1db5580ee5c9": {
     "id": "212b111f-4527-459c-8297-1db5580ee5c9",
     "prev": "76898529-e49e-4663-8d02-8261dfe1d94b",
     "regions": {
      "2e4bd280-3cd6-47d0-9c81-17737b24053b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0c316996-9933-4b3d-82ec-259518dc8bc9",
        "part": "whole"
       },
       "id": "2e4bd280-3cd6-47d0-9c81-17737b24053b"
      }
     }
    },
    "23a7337f-a0cf-4ed4-baa9-ec06bfdc0579": {
     "id": "23a7337f-a0cf-4ed4-baa9-ec06bfdc0579",
     "prev": "e76e9a02-54c1-4ec9-80fb-c611ed398122",
     "regions": {
      "b5721d20-d6f8-4ddb-a5aa-eb16f0cc8893": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "313015a2-b5a9-4136-a8ea-5d011e47d840",
        "part": "whole"
       },
       "id": "b5721d20-d6f8-4ddb-a5aa-eb16f0cc8893"
      }
     }
    },
    "732f1952-ee54-46fb-8067-099512824296": {
     "id": "732f1952-ee54-46fb-8067-099512824296",
     "prev": "0a2d4faf-9fb8-4cee-853b-ed68b90f3f8a",
     "regions": {
      "f31d4597-08ad-4c46-ad52-4bd2d775c624": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "aadfec52-27ca-4541-8920-fa9253d51827",
        "part": "whole"
       },
       "id": "f31d4597-08ad-4c46-ad52-4bd2d775c624"
      }
     }
    },
    "76898529-e49e-4663-8d02-8261dfe1d94b": {
     "id": "76898529-e49e-4663-8d02-8261dfe1d94b",
     "prev": "19091b36-b0e7-49b1-b501-ec05937e0da9",
     "regions": {
      "ec1746fc-aec9-4a7c-8225-9e9ac8d45889": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b3e539be-84e2-49ce-a183-31cfc5c7ce7c",
        "part": "whole"
       },
       "id": "ec1746fc-aec9-4a7c-8225-9e9ac8d45889"
      }
     }
    },
    "8a712017-49b7-449f-8264-43a032ace902": {
     "id": "8a712017-49b7-449f-8264-43a032ace902",
     "prev": "bed9e696-630e-4747-be1c-bc3737ba992f",
     "regions": {
      "1faab517-cd16-4c63-bb01-a67246749d7a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3f14ddf0-4145-4687-9c33-712c3c32520f",
        "part": "whole"
       },
       "id": "1faab517-cd16-4c63-bb01-a67246749d7a"
      }
     }
    },
    "90af992d-eb6d-4496-b2d2-6aa9a95b6a61": {
     "id": "90af992d-eb6d-4496-b2d2-6aa9a95b6a61",
     "prev": "732f1952-ee54-46fb-8067-099512824296",
     "regions": {
      "4f448bec-5be9-4553-88ae-e35ed7612f25": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c445fbfb-b8ab-4e9a-8d13-12231a1c588f",
        "part": "whole"
       },
       "id": "4f448bec-5be9-4553-88ae-e35ed7612f25"
      }
     }
    },
    "bed9e696-630e-4747-be1c-bc3737ba992f": {
     "id": "bed9e696-630e-4747-be1c-bc3737ba992f",
     "prev": "23a7337f-a0cf-4ed4-baa9-ec06bfdc0579",
     "regions": {
      "ac1513f0-404f-492b-8b42-0313e9a753b0": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "18dd2eee-8b6c-4a5e-9539-132d00a7c7e1",
        "part": "whole"
       },
       "id": "ac1513f0-404f-492b-8b42-0313e9a753b0"
      }
     }
    },
    "de6b30f4-2463-4901-92ed-aabad78e5e0f": {
     "id": "de6b30f4-2463-4901-92ed-aabad78e5e0f",
     "prev": "e36b4639-be8c-46f7-a8c9-bcfb134f9fd0",
     "regions": {
      "55ec36e0-362f-4fd3-8060-7cee056039aa": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "c3cf461e-4c9e-4dec-99d2-07bfa79cbe23",
        "part": "whole"
       },
       "id": "55ec36e0-362f-4fd3-8060-7cee056039aa"
      }
     }
    },
    "e36b4639-be8c-46f7-a8c9-bcfb134f9fd0": {
     "id": "e36b4639-be8c-46f7-a8c9-bcfb134f9fd0",
     "prev": "1519a4fa-1588-4644-98de-9c43bf0aceb5",
     "regions": {
      "4c1e9714-9ba0-45fd-8a2f-ef80a5c85c2e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6534d4dc-125f-47e6-a022-cf1e0d277174",
        "part": "whole"
       },
       "id": "4c1e9714-9ba0-45fd-8a2f-ef80a5c85c2e"
      }
     }
    },
    "e76e9a02-54c1-4ec9-80fb-c611ed398122": {
     "id": "e76e9a02-54c1-4ec9-80fb-c611ed398122",
     "prev": "90af992d-eb6d-4496-b2d2-6aa9a95b6a61",
     "regions": {
      "9491b84d-193b-40ff-9321-d21eb1ba88d4": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b64ec10e-fa9d-4f3f-907f-6799611ed6b1",
        "part": "whole"
       },
       "id": "9491b84d-193b-40ff-9321-d21eb1ba88d4"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
